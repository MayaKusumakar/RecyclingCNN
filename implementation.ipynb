{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bc68966",
   "metadata": {},
   "source": [
    "ECS 174 Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66318d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.7' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3.13 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4846e2",
   "metadata": {},
   "source": [
    "#1. Set dataset root and image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027fbad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetRoot = \"DATASET\"\n",
    "# Root folder of the dataset \n",
    "# DATASET/\n",
    "#   TRAIN/\n",
    "#       O/\n",
    "#       R/\n",
    "#   TEST/\n",
    "#       O/\n",
    "#       R/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36166813",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeOfImage = (64, 64) \n",
    "##Preprocess a single image\n",
    "def preprocess_image(path, size= sizeOfImage):\n",
    "    img = Image.open(path).convert(\"RGB\")   # ensure 3 channels (RGB)\n",
    "\n",
    "    # resize to size (width, height)\n",
    "    img = img.resize(size) # PIL resize\n",
    "\n",
    "    # convert to float32 array in [0,1]\n",
    "    img_np = np.array(img).astype(np.float64) / 255.0 # float64 to avoid runtime and convergence warning\n",
    "\n",
    "    # flatten (64 * 64 * 3)\n",
    "    img_flat = img_np.reshape(-1)\n",
    "    return img_flat\n",
    "\n",
    "\n",
    "##Load images for one label (O or R) in a split\n",
    "def load_label(split_name, label_folder, label_value):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    folder = os.path.join(dataSetRoot, split_name, label_folder)\n",
    "\n",
    "    if not os.path.isdir(folder):\n",
    "        print(\"Folder does not exist:\", folder)\n",
    "\n",
    "    for fname in os.listdir(folder):\n",
    "        path = os.path.join(folder, fname)\n",
    "        img_flat = preprocess_image(path)\n",
    "        X_list.append(img_flat)\n",
    "        y_list.append(label_value)\n",
    "\n",
    "    X = np.array(X_list, dtype=np.float64) # float64 to avoid runtime and convergence warning\n",
    "    y = np.array(y_list, dtype=int)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164a1685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all images of label  and combine \n",
    "def load_split(split_name):\n",
    "    X_O, y_O = load_label(split_name, \"O\", 0)\n",
    "    X_R, y_R = load_label(split_name, \"R\", 1)\n",
    "\n",
    "    X = np.concatenate([X_O, X_R], axis=0)\n",
    "    y = np.concatenate([y_O, y_R], axis=0)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99806261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "X_train_full, y_train_full = load_split(\"TRAIN\")\n",
    "X_test, y_test = load_split(\"TEST\")\n",
    "\n",
    "\n",
    "#to check dataset size\n",
    "# print(\"X_train_full shape:\", X_train_full.shape)\n",
    "# print(\"y_train_full counts:\",\n",
    "#       \"O:\", (y_train_full == 0).sum(),\n",
    "#       \"R:\", (y_train_full == 1).sum())\n",
    "\n",
    "# print(\"X_test shape:\", X_test.shape)\n",
    "# print(\"y_test counts:\",\n",
    "#       \"O:\", (y_test == 0).sum(),\n",
    "#       \"R:\", (y_test == 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c56d12",
   "metadata": {},
   "source": [
    "#2 Split train, validation, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8af30a2",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf76fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code\n",
    "#Split into train, validation, test\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    test_size=0.2,\n",
    "    stratify=y_train_full,\n",
    "    random_state=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d7baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standarize Features\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train) #mean/std based on each feature\n",
    "X_val   = scaler.transform(X_val)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca80392",
   "metadata": {},
   "source": [
    "#3. Train Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12148fbc",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/machine-learning/understanding-logistic-regression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad7a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code\n",
    "logRegModel = LogisticRegression(\n",
    "    max_iter=2000,   #up the number of iterations to improve the convergence \n",
    "    random_state=0\n",
    ")\n",
    "logRegModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1967e67f",
   "metadata": {},
   "source": [
    "#4. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b019b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred\n",
    "ytest_pred = logRegModel.predict(X_test)\n",
    "\n",
    "#Test accuracy\n",
    "test_acc = accuracy_score(y_test, ytest_pred)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "# metrics (for report) \n",
    "print(\"\\nTest Metrics report (O = 0, R = 1):\")\n",
    "print(classification_report(y_test, ytest_pred, target_names=[\"O\", \"R\"]))\n",
    "\n",
    "# confusion matrix \n",
    "print(\"\\nConfusion matrix (rows = true, cols = predicted):\")\n",
    "print(confusion_matrix(y_test, ytest_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16611851",
   "metadata": {},
   "source": [
    "#5: Advance Project (PIPELINE)\n",
    "- Take an image the model predicted as recyclable and convert to grayscale\n",
    "- Apply blur, find edges (vertical segments)\n",
    "- Draw a rectangle around it and show it alongside the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e040ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code\n",
    "\n",
    "#used from hw1\n",
    "def rgb_to_gray(image):\n",
    "    return (0.2125 * image[:,:, 0].astype(np.float32) +\n",
    "            0.7154 * image[:,:, 1].astype(np.float32) +\n",
    "            0.0721 * image[:,:, 2].astype(np.float32))\n",
    "\n",
    "def GaussianBlurImage(image, sigma):\n",
    "    ## define Gaussian filter\n",
    "    #got gaussian filter code from filtering.ipynb exactly till convolutio function called\n",
    "    G_filter_size = 2 * int(4 * sigma + 0.5) + 1\n",
    "    gaussian_filter = np.zeros((G_filter_size, G_filter_size), np.float32)\n",
    "    for i in range(G_filter_size):\n",
    "      for j in range(G_filter_size):\n",
    "        x = i - G_filter_size // 2\n",
    "        y = j - G_filter_size // 2\n",
    "        gaussian_filter[i, j] = 1 / (2 * np.pi * sigma ** 2) * np.exp(-(x ** 2 + y ** 2)/(2 * sigma ** 2))\n",
    "\n",
    "    ## and convolve\n",
    "    img_blurred = convolution(image, gaussian_filter) # added filter to function\n",
    "\n",
    "    return img_blurred\n",
    "\n",
    "def SobelImage(image):\n",
    "  #lecture4- Edges: Slide 8\n",
    "  #formula also found on lec4(slide 8) and  (slide 28,29)\n",
    "    gx= np.array([[-1,0,1],[-2,0,2],[-1,0,1]], dtype=np.float32)\n",
    "    gy = np.array([[-1,-2,-1],[0,0,0],[1,2,1]], dtype=np.float32)\n",
    "    #pass sobel filters into convolution\n",
    "    magnitude = np.sqrt((convolution(image, gx)**2) + (convolution(image, gy)**2))\n",
    "    orientation = np.arctan2(-(convolution(image, gy)), convolution(image, gx)) #arctan2 for angle over all quadrants, negative as per slides\n",
    "    vertical_edge = convolution(image, gx)\n",
    "    horizontal_edge = convolution(image, gy)\n",
    "\n",
    "    return magnitude, orientation, vertical_edge, horizontal_edge\n",
    "\n",
    "def convolution(image, filter):\n",
    "    img_convolved = np.zeros_like(image, dtype=np.float32)\n",
    "    ## if needed, pad image\n",
    "     ## convolve\n",
    "     #for boarders, 2D is greyscale and 3D is RBG\n",
    "    padTwoD = ((filter.shape[0]//2, filter.shape[0]//2), (filter.shape[1]//2, filter.shape[1]//2)) #filtering.ipynb\n",
    "    padThreeD = ((filter.shape[0]//2, filter.shape[0]//2), (filter.shape[1]//2, filter.shape[1]//2), (0,0))#filtering.ipynb\n",
    "    imRow = image.shape[0] #from sample_code.py, # of rows\n",
    "    imCol = image.shape[1]\n",
    "\n",
    "    match image.ndim: #ndim = dimensions of array : discussion week 2 notebook\n",
    "      case 3: #3D for color,\n",
    "        return threedConvole (image, filter, padThreeD, imRow, imCol, img_convolved)\n",
    "\n",
    "      case 2: #2D for no color\n",
    "        return greyTwoDConvole (image, filter, padThreeD, imRow, imCol, img_convolved)\n",
    "       \n",
    "def threedConvole (image, filter, padThreeD, imRow, imCol, img_convolved):\n",
    "  imagePad = ownPad(image,padThreeD, 'constant', 0).astype(np.float32)#filtering.ipynb of pad fucntion created\n",
    "  for ch in range(image.shape[2]): #3 loops for each R, B, G\n",
    "    for i in range(imRow):\n",
    "      for j in range(imCol):\n",
    "        frame = imagePad[i:i+filter.shape[0], j:j+filter.shape[1], ch] #slicing in discussion week 2 notebook\n",
    "        img_convolved[i,j,ch] = np.sum(frame * filter)\n",
    "  return img_convolved\n",
    "\n",
    "def greyTwoDConvole (image, filter, padTwoD, imRow, imCol, img_convolved):\n",
    "  imagePad = ownPad(image, padTwoD, 'constant', 0).astype(np.float32)\n",
    "  for i in range(imRow): # two loops for gray scale\n",
    "    for j in range(imCol):\n",
    "      frame = imagePad[i:i+filter.shape[0], j:j+filter.shape[1]] ##slicing in discussion week 2 notebook\n",
    "      img_convolved [i, j] = np.sum(frame * filter)\n",
    "  return img_convolved\n",
    "\n",
    "def ownPad (image, padW, mode, constval):\n",
    "    #for corners\n",
    "    leftTop = padW[0][0]\n",
    "    rightTop = padW[0][1]\n",
    "    leftBottom = padW[1][0]\n",
    "    rightBottom = padW[1][1]\n",
    "    imRow = image.shape[0]\n",
    "    imCol = image.shape[1]\n",
    "\n",
    "    # idea to create bigger matrix with zeros and paste the orignal image into center so expand + darker border\n",
    "    match image.ndim:\n",
    "      case 2:\n",
    "        padIm = np.zeros((imRow + leftTop + rightTop, imCol + leftBottom + rightBottom), dtype=image.dtype) #zero matrix\n",
    "        padIm[leftTop:leftTop+imRow, leftBottom:leftBottom+imCol] = image #orginal image\n",
    "        return padIm\n",
    "\n",
    "      case 3:\n",
    "        padIm = np.zeros((imRow + leftTop + rightTop, imCol + leftBottom + rightBottom, image.shape[2]), dtype=image.dtype) #zero matrix\n",
    "        padIm[leftTop:leftTop+imRow, leftBottom:leftBottom+imCol, :] = image #orginal image\n",
    "        return padIm\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dbbfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recycling detection code\n",
    "\n",
    "def recyclable_image(img_rgb, sigma_blur=2.0):\n",
    "\n",
    "    gray = rgb_to_gray(img_rgb) #Convert to grayscale \n",
    "    guass_blurred = GaussianBlurImage(gray, sigma=sigma_blur)  # H x W\n",
    "    magnitude, orientation, vertical_edge, horizontal_edge = SobelImage(guass_blurred) #edges\n",
    "    vert_abs = np.abs(vertical_edge)\n",
    "\n",
    "# to do: draw rectangle around\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
